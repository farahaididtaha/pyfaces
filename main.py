import argparse
import pickle
import time
import cv2
from detectors.face_detector.opencv_dnn.face_detector import FaceDetector
from detectors.gender_detector.detector import GenderDetector
from detectors.emotion_detector.detector import EmotionDetector
from recognition.dlib.face_recognition import FaceRecognition
from utils.image import resize
from utils.video import FileVideoStream


face_recognizer = pickle.loads(open("models/recognizer.pickle", "rb").read())
le = pickle.loads(open("models/le.pickle", "rb").read())
face_detector = FaceDetector()
gender_detector = GenderDetector()
emotion_detector = EmotionDetector()
face_recognition = FaceRecognition()


def frame_recognize(frame, wait=0):
    t1 = time.time()
    # detecto the face candidates from the image
    # faces, face_confidences is the list of bounding boxes and its confidence
    faces, face_confidences = face_detector.detect(frame)

    # if face not found, we don't proceed further
    if len(faces) < 1:
        return
    t2 = time.time()
    elapsed = f"{(t2 - t1):.2f}"

    # get face encoding from face. face encodings are generated by deep neural network
    encodings = face_recognition.face_encodings(frame, faces)

    # predict, our model is trained on face embeddings using SVM.
    # SVM support probability
    pred_probs = face_recognizer.predict_proba(encodings)

    # Loop face candidates and show boudning box and display gender, name, emotion on the image
    for face_rect, pred_prob in zip(faces, pred_probs):
        # get the probability and index of high probability
        # current model is trained using 4 soccer stars. cristiano, messi, neymar, brazilian ronaldo.
        # pred_probs is 2-d array, and pred_prob is 1-d array. might look like [0.1, 0.2. 0.3, 0.4]
        # meaning current face might be 10% cristiano, 20% messi, 30% neymary, 40% ronaldo
        # so we get the probability and index of high probability
        pred = pred_prob.argmax()
        prob = pred_prob[pred]

        # if the probability is under 0.7, we ignore. 
        if prob < 0.7:
            continue

        # now the probability is higher than 0.7. so we can proceed

        start_x, start_y, end_x, end_y = face_rect
        
        # extract region of interrest, face is numpy array
        face = frame[start_y:end_y, start_x:end_x]
        
        # get gender and its confidence
        gender, gender_confidence = gender_detector.detect(face)

        # get emotional feeling
        emotion = emotion_detector.detect(face)

        # Get the name
        name = le.classes_[pred]

        # draw the rectangle around face region
        cv2.rectangle(img=frame, pt1=(start_x, start_y), pt2=(end_x, end_y),
                      color=(0, 255, 0), thickness=1)
        # put some text
        cv2.putText(img=frame,
                    text=f"{name}: {gender} & {emotion}",
                    org=(start_x, start_y - 10), fontFace=cv2.FONT_HERSHEY_SIMPLEX,
                    fontScale=0.4, thickness=1, color=(0, 255, 0))

    # cv2.putText(img=frame, text=f"Took {elapsed}s ", org=(10, 15),
    #             fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.5,
    #             thickness=1, color=(0, 255, 0))
    cv2.imshow("Faces", frame)
    return cv2.waitKey(wait) & 0xFF


if __name__ == '__main__':
    ap = argparse.ArgumentParser()
    ap.add_argument("-i", "--image", type=str, help="path to the image")
    ap.add_argument("-v", "--video", type=str, help="path to the video")
    args = ap.parse_args()

    # if you specifiy the video we can proceed face recognition and other stuffs on video
    if args.video:
        # open file video stream. leverage queue in order to fasten video processing
        fvs = FileVideoStream(args.video).start()
        time.sleep(3)
        while fvs.more():
            frame = fvs.read()
            # resize the image by maintaing aspect ratio
            frame = resize(frame, width=600)
            # perform job
            key = frame_recognize(frame, wait=1)
            # if `q` is pressed, we stop processing
            if key == ord("q"):
                break

    # if you specify the image instead of video we proceed on image.
    elif args.image:
        # read image from disk
        image = cv2.imread(args.image)
        # anaylze
        frame_recognize(image)
